{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下代码用来实现经典的编码器－解码器代码，并使用 cmn_eng　2.2w条中英文翻译数据，作为实例\n",
    "如果希望更详细的解读，强烈推荐阅读：https://zhuanlan.zhihu.com/p/28054589\n",
    "https://leovan.me/cn/2018/10/seq2seq-and-attention-machanism/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\r\n",
      "Requirement already satisfied: sklearn in /home/zero/anaconda3/lib/python3.6/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /home/zero/anaconda3/lib/python3.6/site-packages (from sklearn) (0.19.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 修复中文显示问题\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "\n",
    "# 判断是否gpu可用,如果可用设置gpu使用显存\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Got it?\\t你懂了吗？\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/cmn-eng.txt', 'r', encoding='utf-8') as f:\n",
    "    contexts = f.readlines()\n",
    "contexts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_pro(contexts):\n",
    "    processed_contexts_en = []\n",
    "    processed_contexts_ch = []\n",
    "    for line in contexts:\n",
    "        en, ch = re.split(r'\\t', line.strip())\n",
    "        # 如果句子过长，则跳过此句\n",
    "#         if len(ch) > 100:\n",
    "#             continue\n",
    "#         print(en, ch)\n",
    "        en = re.sub(r'([\\?\\.\\!\\,¿])', r' \\1', en)\n",
    "#         print(en)\n",
    "        en = re.sub(r'\\s+', ' ', en)\n",
    "        ch = re.sub(r'\\s+', ' ', ch)\n",
    "        en = re.sub(r'[^a-zA-Z\\?\\.\\!\\,。？！，、¿]+', r' ', en)\n",
    "        ch = re.sub(r'[^a-zA-Z\\?\\.\\!\\,。？！，、¿\\u4e00-\\u9fa5]+', r' ', ch)\n",
    "        en = '<start> ' + en[:200] + ' <end>'\n",
    "        ch = '<start> ' + ' '.join([i for i in ch[:100]]) + ' <end>'\n",
    "        \n",
    "        processed_contexts_en.append(en)\n",
    "        processed_contexts_ch.append(ch)\n",
    "    \n",
    "    return processed_contexts_en, processed_contexts_ch\n",
    "\n",
    "\n",
    "processed_contexts_en, processed_contexts_ch = data_pro(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # 创建清理过的输入输出对\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(processed_contexts_en)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(processed_contexts_ch)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 7, 34, 352, 515, 2], [7, 34]], '<start>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n",
    "input_tensor[-1], target_tensor[-1]\n",
    "inp_lang.texts_to_sequences(['<start> hello world <end>', 'head of'])\n",
    "targ_lang.texts_to_sequences(['<start> 你 好 世 界 <end>', '你 好']), targ_lang.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算目标张量的最大长度 （max_length）\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18763 18763 3312 3312\n"
     ]
    }
   ],
   "source": [
    "# 采用 80 - 20 的比例切分训练集和验证集\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.15)\n",
    "\n",
    "# 显示长度\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "45 ----> will\n",
      "4 ----> i\n",
      "91 ----> see\n",
      "7 ----> you\n",
      "117 ----> tomorrow\n",
      "9 ----> ?\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> 我\n",
      "91 ----> 明\n",
      "24 ----> 天\n",
      "36 ----> 能\n",
      "182 ----> 见\n",
      "26 ----> 到\n",
      "7 ----> 你\n",
      "48 ----> 吗\n",
      "13 ----> ？\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 38]), TensorShape([256, 46]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本编码器采用 Bahdanau 注意力\n",
    "p(y_i | y_1,..., y_{i-1}, x) = g(y_{i-1}, s_i, c_i)\n",
    "\n",
    "s_i = f (s_{i-1}, y_{i-1}, c_i)    # 即 s_i与 s_{i-1} , y_{i-1}, c_i 有关, c_i 是 attention 计算得来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.enc_units = enc_units\n",
    "        self.batch_sz = batch_sz\n",
    "        # 返回隐状态 和 整个输出序列\n",
    "        self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True, return_state=True, \n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        # x形状为 (batch_size, seq_len)\n",
    "        # hidden 为初始化向量,形状为 (batch_size, units_dim)\n",
    "        em = self.embedding_dim(x)\n",
    "        output, state = self.gru(em, initial_state = hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(256, 1024), dtype=float32)\n",
      "input shape: (batch size, sequence length) (256, 38)\n",
      "Encoder output shape: (batch size, sequence length, units) (256, 38, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (256, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# 初始化一个样本输入隐向量\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "print(sample_hidden)\n",
    "\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('input shape: (batch size, sequence length) {}'.format(example_input_batch.shape))\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention 实现的是输入两个向量，输出　上下文向量　和　权重，其中权重主要是为了后续 方便　可视化使用,那么，BahdanauAttention中：\n",
    "# Ci = reduce_sum(α * Hs)，　αij = exp(eij) / reduce_sum(exp(eij)), eij = v.tanh(w.s + w.h)\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        \"\"\"\n",
    "        # 初始化需要训练的参数 eij = v.tanh(w.s + w.h)，乘相当于dense操作\n",
    "        \"\"\"\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Ws = tf.keras.layers.Dense(units)\n",
    "        self.Wh = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        \"\"\"\n",
    "        输入: query, values,即S_t-1, hidden_ts\n",
    "        输出: context_vec, attention_weights\n",
    "        \"\"\"\n",
    "        # 这里根据使用方法，query 是 Si中的一个\n",
    "        query = tf.expand_dims(query, axis=1)\n",
    "        # eij = v.tanh(w.s + w.h) 这个式子比较特别，需要使用广播机制\n",
    "        # w . S -> （batch_size, 1, units）, W . h -> (batch_size, seq_len, units)满足广播机制，且 score —> (batch_size, seq_len, 1)\n",
    "        score = self.V(tf.tanh(self.Ws(query) + self.Wh(values)))\n",
    "        # 计算 权重 attention_weight 形状 (batch_size, seq_len, 1)，在 seqence 方向上 转换概率值，所以 axis = 1\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # 计算 content_vector,沿着 axis=1的方向求和\n",
    "        context_vec = tf.reduce_sum(attention_weights * values, axis=1)\n",
    "    \n",
    "        return context_vec, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention 实现的是输入两个向量，输出　上下文向量　和　权重，其中权重主要是为了后续 方便　可视化使用,那么，BahdanauAttention中：\n",
    "# Ci = reduce_sum(α * Hs)，　αij = exp(eij) / reduce_sum(exp(eij)), eij = v.tanh(w.s + w.h)\n",
    "class BahdanauAttention2(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        \"\"\"\n",
    "        # 初始化需要训练的参数 eij = v.tanh(w.s + w.h)，乘相当于dense操作\n",
    "        \"\"\"\n",
    "        super(BahdanauAttention2, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # 注意这里使用了 build 方法,其主要用于根据input_shape创建 layer的Variable\n",
    "        self.Ws = tf.Variable(tf.random.normal(shape=(input_shape[-1],units),stddev=0.01,mean=0,dtype=tf.float32))\n",
    "        self.Wh = tf.Variable(tf.random.normal(shape=(input_shape[-1],units),stddev=0.01,mean=0,dtype=tf.float32))\n",
    "        self.V = tf.Variable(tf.random.normal(shape=(input_shape[-1],1),stddev=0.01,mean=0,dtype=tf.float32))\n",
    "\n",
    "    def call(self, query, values):\n",
    "        \"\"\"\n",
    "        输入: query, values,即S_t-1, hidden_ts\n",
    "        输出: context_vec, attention_weights\n",
    "        \"\"\"\n",
    "        query = tf.expand_dims(query, axis=1)\n",
    "        score = (tf.tanh(query @ self.Ws + values @ self.Wh)) @ self.V\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vec = tf.reduce_sum(attention_weights * values, axis=1)\n",
    "\n",
    "        return context_vec, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (256, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (256, 38, 1)\n",
      "tf.Tensor(\n",
      "[[0.02653692]\n",
      " [0.02648555]\n",
      " [0.02629445]\n",
      " [0.02648648]\n",
      " [0.02666861]\n",
      " [0.02680712]\n",
      " [0.02670638]\n",
      " [0.02647925]\n",
      " [0.02624538]\n",
      " [0.0264552 ]\n",
      " [0.02625991]\n",
      " [0.02619459]\n",
      " [0.02618651]\n",
      " [0.02619937]\n",
      " [0.02621639]\n",
      " [0.02623092]\n",
      " [0.02624122]\n",
      " [0.02624765]\n",
      " [0.0262512 ]\n",
      " [0.0262529 ]\n",
      " [0.02625353]\n",
      " [0.02625361]\n",
      " [0.02625347]\n",
      " [0.02625328]\n",
      " [0.0262531 ]\n",
      " [0.02625297]\n",
      " [0.02625288]\n",
      " [0.02625284]\n",
      " [0.02625282]\n",
      " [0.02625281]\n",
      " [0.02625281]\n",
      " [0.02625282]\n",
      " [0.02625283]\n",
      " [0.02625284]\n",
      " [0.02625285]\n",
      " [0.02625285]\n",
      " [0.02625286]\n",
      " [0.02625286]], shape=(38, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n",
    "print(attention_weights[0])  # 可以看出，没有经过训练的网络，权重参数是比较均衡的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder 输入和输出是什么？ decoder是逐个解码，所以，输入是 x -> (batch_size, 1), decoder侧的隐向量 hidden -> (batch_size, dec_units)\n",
    "# 输出是 下一个状态的隐向量 state 及 output,以及为了方便打印的 attention_weights\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size    # 词表大小\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)    # 词嵌入维度\n",
    "        self.dec_units = dec_units    # 解码器 gru的矩阵的维度，即 hidden_size大小\n",
    "        self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True, \n",
    "                                       return_state=True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # 逐个计算 x,hidden,enc_output计算得到的权重计算后的 context_vec 和 attention_weight\n",
    "        context_vec, attention_weights = self.attention(hidden, enc_output)\n",
    "        # x的维度是 batch_size * 1，经过 embedding 后的维度为 (batch_sz, 1, embedding_size)\n",
    "        x = self.embedding(x)\n",
    "        # 拼接 x 和 context_vec，得到 (batch_size, 1, hidden_size+embedding_dim)\n",
    "        x = tf.concat([tf.expand_dims(context_vec, 1), x], axis=-1)\n",
    "        # 然后将 x 输入到 gru 中\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        # # dense输入可以为2维,也可以为3维，dense会自动在 time_step维度上展开,所以考虑输出后的维度为2维，先进行维度转换\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # 输出形状 (batch_size, vocab_size)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (256, 3407)\n"
     ]
    }
   ],
   "source": [
    "# 简单测试\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 计算mask\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# loss的计算方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.Checkpoint at 0x7f9f222b14e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "tf.train.Checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "    # encoder的最后输出隐状态作为 decoder 初始输入隐状态\n",
    "    dec_hidden = enc_hidden\n",
    "    # 使用 <start> 做初始解码输入\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 教师强制 - 将目标词作为下一个输入\n",
    "    for t in range(1, targ.shape[1]):    # 逐个输入\n",
    "      # 将编码器输出 （enc_output） 传送至解码器\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 使用教师强制，预测阶段正常解码应该用 predictions 作为下一个 time_step 的输入\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "  # 平均 batch_loss\n",
    "  batch_loss = (loss / int(targ.shape[0]))\n",
    "  # 总的可训练参数:\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.3501\n",
      "Epoch 1 Loss 0.2306\n",
      "Time taken for 1 epoch 114.55030298233032 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2081\n",
      "Epoch 2 Loss 0.1894\n",
      "Time taken for 1 epoch 66.3093376159668 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1747\n",
      "Epoch 3 Loss 0.1657\n",
      "Time taken for 1 epoch 64.68755269050598 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1505\n",
      "Epoch 4 Loss 0.1468\n",
      "Time taken for 1 epoch 66.84205842018127 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1336\n",
      "Epoch 5 Loss 0.1309\n",
      "Time taken for 1 epoch 61.34873175621033 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1104\n",
      "Epoch 6 Loss 0.1163\n",
      "Time taken for 1 epoch 67.26499199867249 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1032\n",
      "Epoch 7 Loss 0.1024\n",
      "Time taken for 1 epoch 63.76023817062378 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0920\n",
      "Epoch 8 Loss 0.0895\n",
      "Time taken for 1 epoch 65.85333108901978 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0766\n",
      "Epoch 9 Loss 0.0772\n",
      "Time taken for 1 epoch 64.53484678268433 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0641\n",
      "Epoch 10 Loss 0.0660\n",
      "Time taken for 1 epoch 66.5434992313385 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0545\n",
      "Epoch 11 Loss 0.0555\n",
      "Time taken for 1 epoch 64.1886374950409 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0462\n",
      "Epoch 12 Loss 0.0462\n",
      "Time taken for 1 epoch 66.23439526557922 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0388\n",
      "Epoch 13 Loss 0.0377\n",
      "Time taken for 1 epoch 64.66893744468689 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0280\n",
      "Epoch 14 Loss 0.0302\n",
      "Time taken for 1 epoch 66.92022848129272 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0215\n",
      "Epoch 15 Loss 0.0237\n",
      "Time taken for 1 epoch 64.03110790252686 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0177\n",
      "Epoch 16 Loss 0.0183\n",
      "Time taken for 1 epoch 65.53118562698364 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0132\n",
      "Epoch 17 Loss 0.0140\n",
      "Time taken for 1 epoch 63.87450909614563 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0093\n",
      "Epoch 18 Loss 0.0104\n",
      "Time taken for 1 epoch 66.71492099761963 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0072\n",
      "Epoch 19 Loss 0.0076\n",
      "Time taken for 1 epoch 63.73540949821472 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0050\n",
      "Epoch 20 Loss 0.0056\n",
      "Time taken for 1 epoch 67.96239876747131 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0040\n",
      "Epoch 21 Loss 0.0041\n",
      "Time taken for 1 epoch 64.27736401557922 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0030\n",
      "Epoch 22 Loss 0.0031\n",
      "Time taken for 1 epoch 63.80215525627136 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0023\n",
      "Epoch 23 Loss 0.0024\n",
      "Time taken for 1 epoch 64.23656225204468 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0018\n",
      "Epoch 24 Loss 0.0019\n",
      "Time taken for 1 epoch 64.71033954620361 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0013\n",
      "Epoch 25 Loss 0.0016\n",
      "Time taken for 1 epoch 63.94412660598755 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0012\n",
      "Epoch 26 Loss 0.0014\n",
      "Time taken for 1 epoch 65.11531352996826 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0011\n",
      "Epoch 27 Loss 0.0013\n",
      "Time taken for 1 epoch 62.62712836265564 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0011\n",
      "Epoch 28 Loss 0.0012\n",
      "Time taken for 1 epoch 63.71551465988159 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0008\n",
      "Epoch 29 Loss 0.0011\n",
      "Time taken for 1 epoch 64.27770662307739 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0011\n",
      "Epoch 30 Loss 0.0011\n",
      "Time taken for 1 epoch 64.89520955085754 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0007\n",
      "Epoch 31 Loss 0.0010\n",
      "Time taken for 1 epoch 64.38470911979675 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0009\n",
      "Epoch 32 Loss 0.0010\n",
      "Time taken for 1 epoch 64.60486769676208 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0007\n",
      "Epoch 33 Loss 0.0010\n",
      "Time taken for 1 epoch 64.65810465812683 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0009\n",
      "Epoch 34 Loss 0.0010\n",
      "Time taken for 1 epoch 54.43672037124634 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0007\n",
      "Epoch 35 Loss 0.0013\n",
      "Time taken for 1 epoch 45.20071244239807 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0021\n",
      "Epoch 36 Loss 0.0091\n",
      "Time taken for 1 epoch 45.46178865432739 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0129\n",
      "Epoch 37 Loss 0.0152\n",
      "Time taken for 1 epoch 45.21880769729614 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0085\n",
      "Epoch 38 Loss 0.0078\n",
      "Time taken for 1 epoch 45.45123600959778 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0032\n",
      "Epoch 39 Loss 0.0032\n",
      "Time taken for 1 epoch 45.22094702720642 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0015\n",
      "Epoch 40 Loss 0.0016\n",
      "Time taken for 1 epoch 45.47480654716492 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0012\n",
      "Epoch 41 Loss 0.0011\n",
      "Time taken for 1 epoch 45.19196891784668 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0006\n",
      "Epoch 42 Loss 0.0009\n",
      "Time taken for 1 epoch 45.462403774261475 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0008\n",
      "Epoch 43 Loss 0.0008\n",
      "Time taken for 1 epoch 45.203906536102295 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0009\n",
      "Epoch 44 Loss 0.0008\n",
      "Time taken for 1 epoch 45.44890069961548 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0004\n",
      "Epoch 45 Loss 0.0007\n",
      "Time taken for 1 epoch 45.21276640892029 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0006\n",
      "Epoch 46 Loss 0.0007\n",
      "Time taken for 1 epoch 45.45327425003052 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0004\n",
      "Epoch 47 Loss 0.0007\n",
      "Time taken for 1 epoch 45.2066330909729 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0005\n",
      "Epoch 48 Loss 0.0007\n",
      "Time taken for 1 epoch 45.47233462333679 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0004\n",
      "Epoch 49 Loss 0.0006\n",
      "Time taken for 1 epoch 45.22031545639038 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0004\n",
      "Epoch 50 Loss 0.0007\n",
      "Time taken for 1 epoch 45.475128173828125 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  # 每 2 个周期（epoch），保存（检查点）一次模型\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 翻译\n",
    "评估函数类似于训练循环，不同之处在于在这里我们不使用 `教师强制`。每个时间步的解码器输入是其先前的预测、隐藏层状态和编码器输出。\n",
    "当模型预测 结束标记 时停止预测。\n",
    "存储 每个时间步的注意力权重。\n",
    "请注意：对于一个输入，编码器输出仅计算一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    inputs = inp_lang.texts_to_sequences([sentence])\n",
    "    print('inputs', inputs)\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 存储注意力权重以便后面制图\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 预测的 ID 被输送回模型\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力权重制图函数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恢复最新的检查点并验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9f221ef8d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复检查点目录 （checkpoint_dir） 中最新的检查点\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [[1, 1800, 363, 22, 15, 358, 3, 2]]\n",
      "Input: <start> hello world , it great . <end>\n",
      "Predicted translation: 你 讀 了 ， 很 多 錢 。 <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('<start> hello world , it great . <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [[1, 1273, 251, 22, 7, 33, 358, 122, 2]]\n",
      "Input: <start> hey boy , you are great ! <end>\n",
      "Predicted translation: 老 ， 你 们 是 新 的 。 <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('<start> hey boy , you are great ! <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [[1, 51, 1375, 7, 33, 122, 2]]\n",
      "Input: <start> how lucky you are ! <end>\n",
      "Predicted translation: 你 們 倆 嗎 ？ <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('<start> how lucky you are ! <end>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2-1)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
