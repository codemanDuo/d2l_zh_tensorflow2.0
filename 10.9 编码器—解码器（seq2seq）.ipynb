{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下代码用来实现经典的编码器－解码器代码，并使用 cmn_eng　2.2w条中英文翻译数据，作为实例\n",
    "如果希望更详细的解读，强烈推荐阅读：https://zhuanlan.zhihu.com/p/28054589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Got it?\\t你懂了吗？\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/cmn-eng.txt', 'r', encoding='utf-8') as f:\n",
    "    contexts = f.readlines()\n",
    "contexts[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6927\n",
      "3424\n",
      "max_len_ch:  51\n",
      "max_len_en:  38\n"
     ]
    }
   ],
   "source": [
    "def data_pro(contexts):\n",
    "    processed_contexts_en = []\n",
    "    processed_contexts_ch = []\n",
    "    for line in contexts:\n",
    "        en, ch = re.split(r'\\t', line.strip())\n",
    "#         print(en, ch)\n",
    "        en = re.sub(r'([\\?\\.\\!\\,¿])', r' \\1', en)\n",
    "#         print(en)\n",
    "        en = re.sub(r'\\s+', ' ', en)\n",
    "        ch = re.sub(r'\\s+', ' ', ch)\n",
    "        en = re.sub(r'[^a-zA-Z\\?\\.\\!\\,。？！，、¿]+', r' ', en)\n",
    "        ch = re.sub(r'[^a-zA-Z\\?\\.\\!\\,。？！，、¿\\u4e00-\\u9fa5]+', r' ', ch)\n",
    "        en = '<start> ' + en + ' <end>'\n",
    "        ch = '<start> ' + ' '.join([i for i in ch]) + ' <end>'\n",
    "        \n",
    "        processed_contexts_en.append(en)\n",
    "        processed_contexts_ch.append(ch)\n",
    "    \n",
    "    return processed_contexts_en, processed_contexts_ch\n",
    "\n",
    "max_len_en = set()\n",
    "max_len_ch = set()\n",
    "\n",
    "def get_vocab(processed_contexts_en, processed_contexts_ch):\n",
    "    en_vocab = set()\n",
    "    ch_vocab = set()\n",
    "    for en, ch in zip(processed_contexts_en, processed_contexts_ch):\n",
    "        len_en = len([w for w in re.split(r'\\s', en)])\n",
    "        len_ch = len([w for w in re.split(r'\\s', ch)])\n",
    "        max_len_en.add(len_en)\n",
    "        max_len_ch.add(len_ch)\n",
    "        \n",
    "        en_vocab.update(set([w for w in re.split(r'\\s', en)]))\n",
    "        ch_vocab.update(set([w for w in re.split(r'\\s', ch)]))\n",
    "\n",
    "    return en_vocab, ch_vocab\n",
    "\n",
    "\n",
    "processed_contexts_en, processed_contexts_ch = data_pro(contexts)\n",
    "en_vocab, ch_vocab = get_vocab(processed_contexts_en, processed_contexts_ch)\n",
    "print(len(en_vocab))\n",
    "print(len(ch_vocab))\n",
    "\n",
    "print('max_len_ch: ', max(max_len_ch))\n",
    "print('max_len_en: ', max(max_len_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab2id = {i:k for k,i in enumerate(en_vocab)}\n",
    "ch_vocab2id = {i:k for k,i in enumerate(ch_vocab)}\n",
    "id2en_vocab = {k:i for k,i in enumerate(en_vocab)}\n",
    "id2ch_vocab = {k:i for k,i in enumerate(ch_vocab)}\n",
    "\n",
    "\n",
    "en_vocab2id.get('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data 数据大小： 18763\n",
      "test_data 数据大小： 18763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<start> 你 不 會 遲 到 ， 是 嗎 ？ <end>',\n",
       " '<start> You won t be late , will you ? <end>')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data, test_data = train_test_split(pro_data, test_size=0.15,shuffle=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(processed_contexts_en, processed_contexts_ch, test_size=0.15)\n",
    "print('train_data 数据大小：', len(train_x))\n",
    "print('test_data 数据大小：', len(train_y))\n",
    "\n",
    "train_y[-1], train_x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_tensor(x,y):\n",
    "    x = 1\n",
    "    y = 1\n",
    "    return tf.constant(1),tf.constant(1)\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_x, train_y)).map(data_to_tensor).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本编码器采用 Bahdanau 注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def call(self):\n",
    "        pass\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def call(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def call(self):\n",
    "        passs\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2-1)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
