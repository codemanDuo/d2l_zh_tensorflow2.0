{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 没有GPU注释以下代码\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# # 获取物理gpu, cpu对象\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "# cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "\n",
    "# # 设置当前程序的　物理可见设备范围\n",
    "# tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "\n",
    "# #设置仅在需要时申请：\n",
    "# # for gpu in gpus:\n",
    "# #     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# # 设置在物理gpu上设置虚拟gpu，并用来限制gpu内存使用\n",
    "# tf.config.experimental.set_virtual_device_configuration(\n",
    "#     gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024), tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "\n",
    "# # 获取当前虚拟gpu对象\n",
    "# logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "# print('物理gpu个数: ', len(gpus))\n",
    "# print('总的gpu个数，其中包括括虚拟Logical gpus: ', len(logical_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 定义预处理函数\n",
    "def data_scale(x, y):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    # 由于还没有学卷积，所以需要把图片数据展开,28*28\n",
    "    x = x / 255\n",
    "    x = tf.reshape(x,(784, -1))    # (78,1)\n",
    "    x = tf.squeeze(x)    # 降一个维度\n",
    "    return x, y\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_scale).cache().batch(64)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_scale).cache().batch(64)\n",
    "# next(iter(train_db))  # (shape=(64, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "# 由于还没有学卷积，所以需要把图片数据展开，展开图像的长度为 28*28\n",
    "num_inputs = 784\n",
    "# 分类类别数为: 10 分类\n",
    "num_outputs = 10\n",
    "# 构建两个隐藏层\n",
    "W1 = tf.Variable(tf.random.normal(shape=(num_inputs, 128),mean=0, stddev=0.1, dtype=tf.float32))\n",
    "B1 = tf.Variable(tf.random.normal(shape=(1,128), mean=0.5, stddev=0.1, dtype=tf.float32))\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal(shape=(128, 64),mean=0, stddev=0.1, dtype=tf.float32))\n",
    "B2 = tf.Variable(tf.random.normal(shape=(1,64), mean=0.5, stddev=0.1, dtype=tf.float32))\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal(shape=(64, 10),mean=0, stddev=0.1, dtype=tf.float32))\n",
    "B3 = tf.Variable(tf.random.normal(shape=(1,10), mean=0.5, stddev=0.1, dtype=tf.float32))\n",
    "def hidden_layer_net(X,W1,B1,W2,B2,W3,B3):\n",
    "    h1 = tf.nn.relu(tf.matmul(X, W1) + B1)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, W2) + B2)\n",
    "    out_put = tf.math.softmax(tf.matmul(h2, W3) + B3)\n",
    "    return out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    y = tf.cast(tf.reshape(y, shape=[-1, 1]),dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=y_hat.shape[-1])    \n",
    "    y = tf.cast(tf.reshape(y, shape=[-1, y_hat.shape[-1]]),dtype=tf.int32)\n",
    "    return -tf.math.log(tf.boolean_mask(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数\n",
    "def evaluate_accuracy(data_iter, hidden_layer_net):\n",
    "    acc_sum, n = 0, 0.0\n",
    "    for x, y in data_iter:\n",
    "        yhat = hidden_layer_net(x, W1,B1,W2,B2,W3,B3)\n",
    "        acc_sum += tf.reduce_sum(tf.cast(tf.argmax(yhat, axis=1) == tf.cast(y, dtype=tf.int64), dtype=tf.float32))\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jack\\AppData\\Local\\conda\\conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_grad.py:502: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n",
      "epoch 1, loss 0.5975, train acc 0.785, test acc 0.837\n",
      "epoch 2, loss 0.4303, train acc 0.844, test acc 0.857\n",
      "epoch 3, loss 0.3884, train acc 0.858, test acc 0.869\n",
      "epoch 4, loss 0.3614, train acc 0.868, test acc 0.876\n",
      "epoch 5, loss 0.3413, train acc 0.874, test acc 0.882\n",
      "epoch 6, loss 0.3253, train acc 0.880, test acc 0.887\n",
      "epoch 7, loss 0.3118, train acc 0.885, test acc 0.890\n",
      "epoch 8, loss 0.3003, train acc 0.889, test acc 0.894\n",
      "epoch 9, loss 0.2897, train acc 0.893, test acc 0.897\n",
      "epoch 10, loss 0.2800, train acc 0.897, test acc 0.900\n",
      "epoch 11, loss 0.2717, train acc 0.900, test acc 0.903\n",
      "epoch 12, loss 0.2635, train acc 0.903, test acc 0.905\n",
      "epoch 13, loss 0.2558, train acc 0.906, test acc 0.907\n",
      "epoch 14, loss 0.2486, train acc 0.908, test acc 0.909\n",
      "epoch 15, loss 0.2419, train acc 0.911, test acc 0.912\n",
      "epoch 16, loss 0.2352, train acc 0.914, test acc 0.913\n",
      "epoch 17, loss 0.2290, train acc 0.916, test acc 0.915\n",
      "epoch 18, loss 0.2226, train acc 0.918, test acc 0.916\n",
      "epoch 19, loss 0.2167, train acc 0.920, test acc 0.916\n",
      "epoch 20, loss 0.2112, train acc 0.923, test acc 0.916\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "epoches = 20\n",
    "lr = 1e-3\n",
    "\n",
    "trainer = tf.keras.optimizers.SGD(lr)\n",
    "\n",
    "def train_model(trainer=trainer):\n",
    "    for epoch in range(epoches):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0.0\n",
    "        for (x_in, y_in) in train_db:\n",
    "            # 创建上下文管理器，链接需要计算梯度的函数和变量\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_out = hidden_layer_net(x_in, W1,B1,W2,B2,W3,B3)\n",
    "                loss = tf.reduce_sum(cross_entropy(y_out, y_in))\n",
    "#                 print('loss', loss)\n",
    "            # 自动观测可训练变量\n",
    "            #grads = tape.gradient(loss, [W, B])\n",
    "            grads = tape.gradient(loss, [W1,B1,W2,B2,W3,B3])\n",
    "            if trainer:\n",
    "                # 使用优化器自动更新参数\n",
    "                trainer.apply_gradients(zip(grads, [W1,B1,W2,B2,W3,B3]))\n",
    "            else:\n",
    "                # 手动更新参数\n",
    "                W.assign_sub(grads[0] * lr)\n",
    "                B.assign_sub(grads[1] * lr)\n",
    "            # 计算训练集批量平均准确率和累计平均损失,注意这样做主要是为了方便计算，更合理应该计算全局损失和准确率,但是又需要重新计算，耗时较长\n",
    "            train_acc_sum += tf.reduce_sum(tf.cast(tf.argmax(y_out, axis=1) == tf.cast(y_in, dtype=tf.int64), dtype=tf.float32))\n",
    "#             print(loss)\n",
    "            train_l_sum += loss\n",
    "            # 样本个数：\n",
    "            n += y_in.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_db, hidden_layer_net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_model(trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
