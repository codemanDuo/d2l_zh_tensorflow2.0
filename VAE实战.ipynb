{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# 作图函数\n",
    "def save_images(imgs, name):\n",
    "    new_im = Image.new('L', (280, 280))\n",
    "    index = 0\n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = imgs[index]\n",
    "            im = Image.fromarray(im, mode='L')\n",
    "            new_im.paste(im, (i, j))\n",
    "            index += 1\n",
    "    new_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 20\n",
    "batchsz = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255, x_test.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db = train_db.shuffle(20).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_db = test_db.batch(batchsz)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        # encoder\n",
    "        self.e1 = keras.layers.Dense(128)\n",
    "        print(self.e1)\n",
    "        self.e2 = keras.layers.Dense(z_dim)   # get mean prediction\n",
    "        self.e3 = keras.layers.Dense(z_dim)   #  get mean prediction\n",
    "        \n",
    "        # decoder\n",
    "        self.fc4 = keras.layers.Dense(128)\n",
    "        self.fc5 = keras.layers.Dense(784)\n",
    "    \n",
    "    def encoder(self, inputs):\n",
    "        h = self.e1(inputs)\n",
    "        h = tf.nn.relu(h)\n",
    "        # get_mean\n",
    "        mean = self.e2(h)\n",
    "        # get_variance\n",
    "        log_var = self.e3(h)    # 一般方差做一个log，方便计算\n",
    "        \n",
    "        return mean, log_var\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        out = tf.nn.relu(self.fc4(z))\n",
    "        out = self.fc5(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def reparameterize(self, mean, log_var):\n",
    "        eps = tf.random.normal(tf.shape(log_var))\n",
    "        \n",
    "        std = tf.exp(log_var)**0.5    # 开根号\n",
    "        \n",
    "        z = mean + std * eps\n",
    "        \n",
    "        return z\n",
    "        \n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 784] -> [b, z_dim], [b, z_dim]\n",
    "        mean, log_var = self.encoder(inputs)\n",
    "        # trick: reparameterization trick，采样\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        # 返回 x 的同时，返回 mean和val作为约束\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001E70461BDD8>\n",
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1408      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  101136    \n",
      "=================================================================\n",
      "Total params: 205,604\n",
      "Trainable params: 205,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 0 kl_div: 0.0004456816241145134 rec_loss: tf.Tensor(0.6991839, shape=(), dtype=float32)\n",
      "0 10 kl_div: 0.005508009344339371 rec_loss: tf.Tensor(0.62022746, shape=(), dtype=float32)\n",
      "0 20 kl_div: 0.010254837572574615 rec_loss: tf.Tensor(0.5123347, shape=(), dtype=float32)\n",
      "0 30 kl_div: 0.013263970613479614 rec_loss: tf.Tensor(0.44646972, shape=(), dtype=float32)\n",
      "0 40 kl_div: 0.014139354228973389 rec_loss: tf.Tensor(0.4165764, shape=(), dtype=float32)\n",
      "0 50 kl_div: 0.012833093293011189 rec_loss: tf.Tensor(0.40584102, shape=(), dtype=float32)\n",
      "0 60 kl_div: 0.011167282238602638 rec_loss: tf.Tensor(0.383286, shape=(), dtype=float32)\n",
      "0 70 kl_div: 0.010420494712889194 rec_loss: tf.Tensor(0.3808412, shape=(), dtype=float32)\n",
      "0 80 kl_div: 0.00973714143037796 rec_loss: tf.Tensor(0.3800937, shape=(), dtype=float32)\n",
      "0 90 kl_div: 0.00986585021018982 rec_loss: tf.Tensor(0.3616586, shape=(), dtype=float32)\n",
      "0 100 kl_div: 0.009662370197474957 rec_loss: tf.Tensor(0.36438423, shape=(), dtype=float32)\n",
      "0 110 kl_div: 0.00990988127887249 rec_loss: tf.Tensor(0.3487089, shape=(), dtype=float32)\n",
      "1 0 kl_div: 0.008958868682384491 rec_loss: tf.Tensor(0.34695184, shape=(), dtype=float32)\n",
      "1 10 kl_div: 0.008545229211449623 rec_loss: tf.Tensor(0.3487004, shape=(), dtype=float32)\n",
      "1 20 kl_div: 0.009131581522524357 rec_loss: tf.Tensor(0.33744678, shape=(), dtype=float32)\n",
      "1 30 kl_div: 0.009020808152854443 rec_loss: tf.Tensor(0.33111477, shape=(), dtype=float32)\n",
      "1 40 kl_div: 0.00944601371884346 rec_loss: tf.Tensor(0.3246956, shape=(), dtype=float32)\n",
      "1 50 kl_div: 0.0091398311778903 rec_loss: tf.Tensor(0.32741588, shape=(), dtype=float32)\n",
      "1 60 kl_div: 0.008940251544117928 rec_loss: tf.Tensor(0.3233453, shape=(), dtype=float32)\n",
      "1 70 kl_div: 0.008692036382853985 rec_loss: tf.Tensor(0.32529247, shape=(), dtype=float32)\n",
      "1 80 kl_div: 0.008359663188457489 rec_loss: tf.Tensor(0.32977864, shape=(), dtype=float32)\n",
      "1 90 kl_div: 0.008540695533156395 rec_loss: tf.Tensor(0.31653205, shape=(), dtype=float32)\n",
      "1 100 kl_div: 0.008356092497706413 rec_loss: tf.Tensor(0.32648036, shape=(), dtype=float32)\n",
      "1 110 kl_div: 0.008367106318473816 rec_loss: tf.Tensor(0.31983262, shape=(), dtype=float32)\n",
      "2 0 kl_div: 0.007738078944385052 rec_loss: tf.Tensor(0.3185225, shape=(), dtype=float32)\n",
      "2 10 kl_div: 0.007379511836916208 rec_loss: tf.Tensor(0.32321322, shape=(), dtype=float32)\n",
      "2 20 kl_div: 0.007994227111339569 rec_loss: tf.Tensor(0.31430835, shape=(), dtype=float32)\n",
      "2 30 kl_div: 0.00792311504483223 rec_loss: tf.Tensor(0.31203556, shape=(), dtype=float32)\n",
      "2 40 kl_div: 0.00808587484061718 rec_loss: tf.Tensor(0.30997983, shape=(), dtype=float32)\n",
      "2 50 kl_div: 0.007888459600508213 rec_loss: tf.Tensor(0.31453574, shape=(), dtype=float32)\n",
      "2 60 kl_div: 0.007775797042995691 rec_loss: tf.Tensor(0.30994636, shape=(), dtype=float32)\n",
      "2 70 kl_div: 0.007907802239060402 rec_loss: tf.Tensor(0.31460783, shape=(), dtype=float32)\n",
      "2 80 kl_div: 0.007443633861839771 rec_loss: tf.Tensor(0.3193483, shape=(), dtype=float32)\n",
      "2 90 kl_div: 0.007641340605914593 rec_loss: tf.Tensor(0.3088593, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = VAE()\n",
    "\n",
    "model.build(input_shape=(None, 784))\n",
    "model.summary()\n",
    "optimizer = tf.optimizers.Adam(0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_rec_logits, mean, log_var = model(x)\n",
    "            rec_loss = tf.losses.binary_crossentropy(x, x_rec_logits, from_logits=True)\n",
    "            rec_loss = tf.reduce_mean(rec_loss)\n",
    "            # compute kl divergence (mean, val) ~ N(0, 1)\n",
    "            kl_div = -0.5 * (log_var + 1 - mean ** 2 - tf.exp(log_var))\n",
    "            kl_div = tf.reduce_mean(kl_div) / x.shape[0]\n",
    "            # loss \n",
    "            loss = rec_loss + 1.0 * kl_div\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print(epoch, step, 'kl_div:', float(kl_div), 'rec_loss:', rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
