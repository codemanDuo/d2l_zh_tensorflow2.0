{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "# # 获取物理gpu, cpu对象\n",
    "# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "# cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "\n",
    "# # 设置当前程序的　物理可见设备范围\n",
    "# tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "\n",
    "# #设置仅在需要时申请：\n",
    "# # for gpu in gpus:\n",
    "# #     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# # 设置在物理gpu上设置虚拟gpu，并用来限制gpu内存使用\n",
    "# tf.config.experimental.set_virtual_device_configuration(\n",
    "#     gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024), tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "\n",
    "# # 获取当前虚拟gpu对象\n",
    "# logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "# print('物理gpu个数: ', len(gpus))\n",
    "# print('总的gpu个数，其中包括括虚拟Logical gpus: ', len(logical_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6,kernel_size=5,activation='sigmoid',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=16,kernel_size=5,activation='sigmoid'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(84,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10,activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d ,output shape\t: (1, 24, 24, 6)\n",
      "max_pooling2d ,output shape\t: (1, 12, 12, 6)\n",
      "conv2d_1 ,output shape\t: (1, 8, 8, 16)\n",
      "max_pooling2d_1 ,output shape\t: (1, 4, 4, 16)\n",
      "flatten ,output shape\t: (1, 256)\n",
      "dense ,output shape\t: (1, 120)\n",
      "dense_1 ,output shape\t: (1, 84)\n",
      "dense_2 ,output shape\t: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1,28,28,1))\n",
    "for layer in net.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.name, ',output shape\\t:', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=249, shape=(128, 28, 28, 1), dtype=float32, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取数据\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "def data_scale(x, y):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "#     x = x / 255\n",
    "    # 注意这里需要增加一个 通道数 维度\n",
    "    x = tf.reshape(x, (x.shape[0],x.shape[1],-1))\n",
    "    return x, y\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60).map(data_scale).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(60).map(data_scale).batch(128)\n",
    "next(iter(train_db))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "net.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.7549 - accuracy: 0.7017 - val_loss: 0.5256 - val_accuracy: 0.8017\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.4620 - accuracy: 0.8237 - val_loss: 0.4471 - val_accuracy: 0.8267\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.4108 - accuracy: 0.8439 - val_loss: 0.4388 - val_accuracy: 0.8325\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.3953 - accuracy: 0.8497 - val_loss: 0.4228 - val_accuracy: 0.8376\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.3669 - accuracy: 0.8596 - val_loss: 0.3903 - val_accuracy: 0.8556\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3593 - accuracy: 0.8634 - val_loss: 0.4514 - val_accuracy: 0.8297\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3637 - accuracy: 0.8610 - val_loss: 0.3859 - val_accuracy: 0.8564\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3422 - accuracy: 0.8694 - val_loss: 0.3848 - val_accuracy: 0.8557\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3307 - accuracy: 0.8736 - val_loss: 0.3750 - val_accuracy: 0.8632\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3187 - accuracy: 0.8779 - val_loss: 0.3747 - val_accuracy: 0.8645\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3125 - accuracy: 0.8798 - val_loss: 0.3897 - val_accuracy: 0.8572\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3119 - accuracy: 0.8801 - val_loss: 0.3896 - val_accuracy: 0.8643\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3393 - accuracy: 0.8695 - val_loss: 0.3678 - val_accuracy: 0.8651\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.3236 - accuracy: 0.8761 - val_loss: 0.3617 - val_accuracy: 0.8647 loss: 0.3235 - accuracy - ETA: 0s - loss: 0.3239 - accuracy: \n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.3032 - accuracy: 0.8827 - val_loss: 0.3748 - val_accuracy: 0.8639\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.3039 - accuracy: 0.8827 - val_loss: 0.3700 - val_accuracy: 0.8614\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2950 - accuracy: 0.8871 - val_loss: 0.3562 - val_accuracy: 0.8707\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2898 - accuracy: 0.8880 - val_loss: 0.3734 - val_accuracy: 0.8624\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2832 - accuracy: 0.8909 - val_loss: 0.3552 - val_accuracy: 0.8708\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2845 - accuracy: 0.8886 - val_loss: 0.3523 - val_accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236cf056f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = net.fit_generator(generator=train_db, epochs=20, validation_data=test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
